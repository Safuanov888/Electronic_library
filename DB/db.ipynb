{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "468a821d-1918-4f2e-a379-9709ab3defce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = 'D:\\\\HuggingFace'\n",
    "os.environ['TRANSFORMERS_CACHE'] = os.environ['HF_HOME']\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = os.environ['HF_HOME'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85958e22-59fd-49aa-ae81-154b133ab945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Турбо\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8caeb919-5467-48c2-a95a-291523842389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(query):\n",
    "    answer = pipe(query, classes, multi_label=False)\n",
    "    return [answer['labels'], answer['scores']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2897f3af-9f18-4f8a-9681-4aa40537e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, window_size=3, overlap=1):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(sentences), window_size-overlap):\n",
    "        chunks.append(\" \".join(sentences[i:i+window_size]))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0499eb5d-e251-4021-a432-a378addca8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(document):\n",
    "    # Делим документ\n",
    "    chunks = chunk_text(document)\n",
    "\n",
    "    # Предсказываем каждую часть\n",
    "    preds = []\n",
    "    for chun in chunks:\n",
    "        preds.append(get_pred(chun))\n",
    "        \n",
    "    # Считаем взвешенную метрику\n",
    "    scores = defaultdict(float)\n",
    "    for pred in preds:\n",
    "        for label, score in zip(pred[0], pred[1]):\n",
    "            scores[label] += score\n",
    "\n",
    "    return max(scores, key=scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00cec5fd-7136-4d72-9ca7-36c1b2471bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_info(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        text = ''.join([page.extract_text() for page in reader.pages])\n",
    "    # Служебная информация\n",
    "    text = re.sub(r'ISSN\\s+\\d{4}-\\d{3,4}[^\\n]*', '', text)\n",
    "    text = re.sub(r'\\d{4};\\d{2}\\(\\d+\\):\\d+–\\d+', '', text)\n",
    "\n",
    "    # Авторы\n",
    "    text = re.sub(r'[А-ЯЁ][а-яё]+\\s+[А-ЯЁ][\\.\\s]+\\s*[А-ЯЁ][\\.\\s]*', '', text)\n",
    "    text = re.sub(r'[А-ЯЁ][а-яё]+\\s+[А-ЯЁ][а-яё]+\\s+[А-ЯЁ][\\.\\s]+\\s*[А-ЯЁ][\\.\\s]*', '', text)\n",
    "    text = re.sub(r'\\d+[\\s\\w\\.,–-]+(университет|институт|академия|центр)[^\\n]*', '', text)\n",
    "\n",
    "    # Сноски в квадратных скобках\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)  # [1], [2]\n",
    "    text = re.sub(r'\\[\\d+[,-]\\d+\\]', '', text)  # [1-3], [4,5]\n",
    "    text = re.sub(r'\\[[A-Za-z]+\\d*\\]', '', text)  # [A1], [B]\n",
    "    \n",
    "    # email\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # английские разделы \n",
    "    text = re.sub(r'Abstract[^\\n]*[\\s\\S]*?(?=\\n[А-ЯЁ]|$)', '', text)\n",
    "    text = re.sub(r'Keywords[^\\n]*[\\s\\S]*?(?=\\n[А-ЯЁ]|$)', '', text)\n",
    "    text = re.sub(r'For citation[^\\n]*[\\s\\S]*?(?=\\n[А-ЯЁ]|$)', '', text)\n",
    "    \n",
    "    # ссылки\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    text = re.sub(r'DOI:\\s*\\S+', '', text)\n",
    "    \n",
    "    # библиография\n",
    "    text = re.sub(r'Список\\s+источников[\\s\\S]*', '', text)\n",
    "    text = re.sub(r'References[\\s\\S]*', '', text)\n",
    "    \n",
    "    # спец.символы\n",
    "    text = text.replace('\\xa0', ' ').replace('•', '')\n",
    "    text = re.sub(r'-\\s+', '', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'•\\s*\\n', '', text)\n",
    "    \n",
    "    # оставшиеся английские фрагменты\n",
    "    text = re.sub(r'(?:[A-Za-z-]+\\s){3,}[A-Za-z-]*', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74ed6485-7396-4836-a78c-8d3625011ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Подключение к PostgreSQL успешно\n",
      "✅ Таблица 'articles' создана или уже существует\n",
      "✅ Статья 'https://elibrary.ru/download/elibrary_26738028_39746529.pdf' добавлена в класс 'Art'\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import psycopg2\n",
    "from psycopg2 import sql, errors\n",
    "from collections import defaultdict\n",
    "from nltk import sent_tokenize\n",
    "import PyPDF2\n",
    "import pathlib\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"Electronic_library\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Turbo\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"zero-shot-classification\", \n",
    "    model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\", \n",
    "    hypothesis_template=\"Определи тему научной статьи '{}'\", \n",
    "    disable_hf_device_logging=True,\n",
    ")\n",
    "\n",
    "classes = ['Education', 'Art', 'Sport', 'Chemical', 'Space']\n",
    "\n",
    "def create_connection():\n",
    "    \"\"\"Устанавливает соединение с PostgreSQL.\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        print(\"✅ Подключение к PostgreSQL успешно\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка подключения: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_table(conn):\n",
    "    \"\"\"Создает таблицу для хранения классифицированных статей.\"\"\"\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS articles (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        url TEXT NOT NULL UNIQUE,\n",
    "        education BOOLEAN DEFAULT FALSE,\n",
    "        art BOOLEAN DEFAULT FALSE,\n",
    "        sport BOOLEAN DEFAULT FALSE,\n",
    "        chemical BOOLEAN DEFAULT FALSE,\n",
    "        space BOOLEAN DEFAULT FALSE\n",
    "    );\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(create_table_query)\n",
    "            conn.commit()\n",
    "        print(\"✅ Таблица 'articles' создана или уже существует\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка создания таблицы: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "\n",
    "def predict_class(text):\n",
    "    \"\"\"Определяет класс текста.\"\"\"\n",
    "    try:\n",
    "        result = aggregate(text)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка классификации: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def insert_article(conn, url, text):\n",
    "    \"\"\"Добавляет статью в БД, устанавливая True в нужный столбец, остальные NULL.\"\"\"\n",
    "    predicted_class = predict_class(text)\n",
    "    if not predicted_class:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Создаем словарь для обновления (все NULL, кроме predicted_class)\n",
    "            data = {class_name.lower(): (True if class_name == predicted_class else None) \n",
    "                   for class_name in classes}\n",
    "            data['url'] = url\n",
    "\n",
    "            # Формируем SQL-запрос\n",
    "            columns = sql.SQL(', ').join(map(sql.Identifier, data.keys()))\n",
    "            values = sql.SQL(', ').join([sql.Placeholder()] * len(data))\n",
    "            \n",
    "            query = sql.SQL(\"\"\"\n",
    "            INSERT INTO articles ({columns})\n",
    "            VALUES ({values})\n",
    "            ON CONFLICT (url) DO UPDATE SET\n",
    "                {update_clause}\n",
    "            \"\"\").format(\n",
    "                columns=columns,\n",
    "                values=values,\n",
    "                update_clause=sql.SQL(', ').join([\n",
    "                    sql.SQL(\"{} = EXCLUDED.{}\").format(\n",
    "                        sql.Identifier(k),\n",
    "                        sql.Identifier(k)\n",
    "                    ) for k in data.keys() if k != 'url'\n",
    "                ])\n",
    "            )\n",
    "            \n",
    "            cursor.execute(query, list(data.values()))\n",
    "            conn.commit()\n",
    "\n",
    "        print(f\"✅ Статья '{url}' добавлена в класс '{predicted_class}'\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка вставки: {e}\")\n",
    "        conn.rollback()\n",
    "        return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    conn = create_connection()\n",
    "    if conn:\n",
    "        create_table(conn)\n",
    "\n",
    "        insert_article(\n",
    "            conn,\n",
    "            url=\"https://elibrary.ru/download/elibrary_26738028_39746529.pdf\",\n",
    "            text=process_info(\"art.pdf\")\n",
    "        )\n",
    "\n",
    "        conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
